ggpairs(Ventas[, c("bedrooms", "bathrooms", "floors", "sqft_living", "price")])
dev.off()
# Excluiremos del modelo las siguientes variables:
# - bedrooms y bathrooms: porque están muy correlacionadas con sqft_living (0.60 y 0.76) y entre sí (0.53).
### -------------------------------------------------------------------------
### Analizamos las variables relacionadas con el exterior de la vivienda: waterfront y view
### -------------------------------------------------------------------------
table(Ventas$waterfront)
table(Ventas$view)
ggpairs(Ventas[, c("waterfront", "view", "price")])
dev.off()
png("images/ggpairs_exterior.png")
ggpairs(Ventas[, c("waterfront", "view", "price")])
dev.off()
# Excluiremos del modelo las siguientes variables:
# - waterfront y view: porque su correlación con price es bastante baja.
table(Ventas$sqft_lot)
table(Ventas$sqft_above)
table(Ventas$sqft_basement==0)
table(Ventas$sqft_living15)
table(Ventas$sqft_lot15)
# La variable sqft_basement parece hacer referencia a la superficie del "sótano", y vemos que hay 10.552 viviendas que tienen ese valor a 0, por lo que vamos a crear una variable dummy.
Ventas$basement<-(ifelse(Ventas$sqft_basement==0,0,1))
ggpairs(Ventas[, c("sqft_lot", "sqft_above", "basement", "sqft_living15", "sqft_lot15", "sqft_living", "price")])
dev.off()
png("images/ggpairs_superficie.png")
ggpairs(Ventas[, c("sqft_lot", "sqft_above", "basement", "sqft_living15", "sqft_lot15", "sqft_living", "price")])
dev.off()
# Excluiremos del modelo las siguientes variables:
# - sqft-living15: por su alta correlación con sqft-living (0.76).
# - sqft-lot15: por su alta correlación con sqft-lot (0.73).
# - sqft-above: por su casi perfecta correlación con sqft-living (0.88)
# - basement: por su escasa correlación con price.
### -------------------------------------------------------------------------
### Analizamos las variables relacionadas con fechas: yr_built, yr_renovated, date
### -------------------------------------------------------------------------
table(Ventas$date)
table(Ventas$yr_built)
table(Ventas$yr_renovated==0)
# Convertimos la información de la variable date en fechas válidas
Ventas$date<-as.Date(Ventas$date,"%Y%m%d")
# Vemos que hay 724 viviendas reformadas y 16.660 sin reformar, por lo que vamos a crear una variable dummy.
Ventas$renovated<-(ifelse(Ventas$yr_renovated==0,0,1))
ggpairs(Ventas[, c("yr_built", "renovated", "date", "price")])
dev.off()
png("images/ggpairs_fechas.png")
ggpairs(Ventas[, c("yr_built", "renovated", "date", "price")])
dev.off()
# Excluiremos del modelo las siguientes variables:
# - yr_built, yr_renovated y date: por su baja correlación con price.
### -------------------------------------------------------------------------
### Analizamos las variables relacionadas con la localización de la vivienda: zipcode, lat, long
### -------------------------------------------------------------------------
table(Ventas$zipcode)
table(Ventas$lat)
table(Ventas$long)
ggpairs(Ventas[, c("zipcode", "lat", "long", "price")])
dev.off()
png("images/ggpairs_localizacion.png")
ggpairs(Ventas[, c("zipcode", "lat", "long", "price")])
dev.off()
# Excluiremos del modelo las siguientes variables:
# - Zipcode: porque tiene muchos niveles (70).
### -------------------------------------------------------------------------
### Analizamos las variables completamente desconocidas: condition, grade
### -------------------------------------------------------------------------
table(Ventas$condition)
table(Ventas$grade)
ggpairs(Ventas[, c("condition", "grade", "price")])
dev.off()
png("images/ggpairs_desconocidas.png")
ggpairs(Ventas[, c("condition", "grade", "price")])
dev.off()
# Excluiremos del modelo las siguientes variables:
# - condition: por su baja correlación con price.
Ventas2 <- Ventas
variables_a_excluir <- c("id", "price", "bedrooms", "bathrooms", "sqft-living15", "sqft-lot15", "sqft-above", "yr_built", "yr_renovated", "renovated", "date", "waterfront", "view", "condition", "sqft_basement", "basement")
Ventas2 <- Ventas2[ , !(names(Ventas2) %in% variables_a_excluir)]
### Creamos los conjuntos de entrenamiento y prueba
set.seed(12357)
subsets = sample.split(Ventas2$price_log, SplitRatio = 0.7)
Train = subset(Ventas2, subsets == TRUE)
Test = subset(Ventas2, subsets == FALSE)
### Obtenemos el modelo y analizamos los residuos
modelo = lm(price_log~., data=Train)
summary(modelo)
par(mfrow = c(2, 2))
plot(modelo)
dev.off()
png("images/modelo_train.png")
par(mfrow = c(2, 2))
plot(modelo)
dev.off()
# Parecen cumplirse las hipotesis de normalidad y hommocedasticidad.
### Hacemos la estimación robusta:
modelo_r <- rlm(price_log~., data=Train)
summary(modelo_r)
coef(modelo)
coef(modelo_r)
# No hay diferencias considerables entre los estimadores OLS y estimadores OLS robustos, con la excepción de floors. El estimador de floors parece no converger, se ejecutará la regresión  Ridge.
Train$prediccion = predict(modelo, type="response")
R2_Train = 1 - sum((Train$price_log-Train$prediccion)^2)/sum((Train$price_log-mean(Train$price_log))^2)
R2_Train
Test$prediccion = predict(modelo,newdata=Test,type="response")
R2_Test = 1 - sum((Test$price_log-Test$prediccion)^2)/sum((Test$price_log-mean(Test$price_log))^2)
R2_Test
summary(modelo)$r.squared
summary(modelo)$adj.r.squared
# En segundo lugar, se obtiene la matriz de correlaciones, para estudiar las relaciones entre variables independientes.
dropscor <- c("lat","long","zipcode", "price_log", "logsqft_lot", "prediccion")
# se eliman aquellas variables creadas en el exploratorio asi como las que determina la función alias
traincor<-Train[ , !(names(Train) %in% dropscor)]
cor(traincor)
variables <- c("bedrooms", "bathrooms", "sqft-living15", "sqft-lot15", "sqft-above", "yr_built", "yr_renovated", "renovated", "date", "waterfront", "view", "condition", "sqft_basement", "basement")
Lambda = 5
Pruebas = 100
Coeficientes = matrix(0, nrow=Pruebas, ncol=length(variables)+1)
Coeficientes = as.data.frame(Coeficientes)
colnames(Coeficientes) = c("termino_independiente", variables)
SCE_TRAIN1_modeloRidge = c()
STC_TRAIN1_modeloRidge = c()
R2_TRAIN1_modeloRidge = c()
SCE_TEST1_modeloRidge = c()
STC_TEST1_modeloRidge = c()
R2_TEST1_modeloRidge = c()
for (i in 1:Pruebas) {
modelo_glmnet=glmnet(x=as.matrix(Train[,variables]),y=Train$price_log,lambda=Lambda*(i-1)/Pruebas,alpha=0)
Coeficientes[i,]=c(modelo_glmnet$a0,as.vector(modelo_glmnet$beta))
prediccionesTrain=predict(modelo_glmnet,newx = as.matrix(Train[,variables]))
SCE_TRAIN1_modeloRidge=c(SCE_TRAIN1_modeloRidge,sum((Train$price_log-prediccionesTrain)^2))
STC_TRAIN1_modeloRidge=c(STC_TRAIN1_modeloRidge,sum((Train$price_log-mean(Train$price_log))^2))
R2_TRAIN1_modeloRidge=c(R2_TRAIN1_modeloRidge,1-sum((Train$price_log-prediccionesTrain)^2)/sum((Train$price_log-mean(Train$price_log))^2))
prediccionesTest=predict(modelo_glmnet,newx = as.matrix(Test[,variables]))
SCE_TEST1_modeloRidge=c(SCE_TEST1_modeloRidge,sum((Test$price_log-prediccionesTest)^2))
STC_TEST1_modeloRidge=c(STC_TEST1_modeloRidge,sum((Test$price_log-mean(Test$price_log))^2))
R2_TEST1_modeloRidge=c(R2_TEST1_modeloRidge,1-sum((Test$price_log-prediccionesTest)^2)/sum((Test$price_log-mean(Test$price_log))^2))
}
colores=rainbow(length(variables))
plot(Coeficientes[,1],type="l",col="white",ylim=c(-4,2))
for (i in 1:length(variables)){
lines(Coeficientes[,i+1],type="l",col=colores[i])
}
plot(R2_TRAIN1_modeloRidge,col="red",type="l", ylim=c(0,1))
lines(R2_TEST1_modeloRidge,col="blue",type="l")
max(R2_TEST1_modeloRidge)
which(R2_TEST1_modeloRidge==max(R2_TEST1_modeloRidge))
Caso=62
R2_TRAIN1_modeloRidge[Caso]
R2_TEST1_modeloRidge[Caso]
Lambda*(Caso-1)/Pruebas
Coeficientes[Caso,]
modelo_glmnet=glmnet(x=as.matrix(Train[,variables]),y=Train$price_log,lambda=Lambda*(Caso-1)/Pruebas,alpha=0)
modelo_glmnet$beta
R2_TRAIN1_modeloRidge[Caso]
R2_TEST1_modeloRidge[Caso]
# Comparando los coeficientes del OLS original con los obtenidos de la regresión Ridge, los coeficientes difieren bastante. Se ha corregido por multicolinealidad.
coef(modelo)
coef(modelo_glmnet)
# Comparando los coeficientes del OLS original con los obtenidos de la regresión Ridge, los coeficientes difieren bastante. Se ha corregido por multicolinealidad.
coef(modelo)
coef(modelo_glmnet)
#Las predicciones se encuentran en las matrices
prediccionesTrain
prediccionesTest
# Medición de la accuracy vía Mean Squarred Error
y_hat = prediccionesTest
y= Test$price_log
mse<-(sum((y_hat-y)^2))/(nrow(Test))
sprintf("MSE para el model Ridge: %f", mse)
ggplot(data.frame(y_hat, y), aes(x=y_hat, y=y)) +
geom_point(color='blue') +
geom_abline(color='red', linetype=2) +
xlab("Predicted") +
ylab("Actual") +
ggtitle("Accuracy del Modelo Ridge")
### -------------------------------------------------------------------------
### Añadir columna de price al fichero house_test.csv
### -------------------------------------------------------------------------
# Cargamos los datos
house_test = read.csv("data/house_test.csv", stringsAsFactors=FALSE, sep=",")
# Revisamos los datos cargados
str(house_test)
head(house_test)
summary(house_test)
house_test$basement <- (ifelse(house_test$sqft_basement==0,0,1))
house_test$renovated <- (ifelse(house_test$yr_renovated==0,0,1))
# Se necesita un model objeto para poder utilizar la función predict. Con los coeficientes estimados del modelo Ridge no es posible realizarlo, con esta funcíon, sin construir manualmente el vector. Podría realizarse con el modelo OLS, antes de corregir por colinealidad -aunque sabemos que algunos estimadres no son muy robustos. Y mediante una función inversa de log calcular el price.
house_test$prediccionOLS==predict(modelo,newdata=house_test,type="response") #no la vamos a ejecutar
rcoefi<-coef(modelo_glmnet) # Alternativamente se construye un vector con los coeficientes de la regresíon Ridge
ridgecoef<-c(0,rcoefi[2], rcoefi[3], rcoefi[4], rcoefi[5],rcoefi[6], rcoefi[7],rcoefi[8], 0, rcoefi[9], 0, 0, 0,0, rcoefi[10], rcoefi[11], rcoefi[12],0,0, rcoefi[13], rcoefi[14])
# Multiplicación de matrices para la obtención de price en el data set house_test
variables_a_eliminar <- c("date")
house_test_prediction<-house_test[ , !(names(house_test) %in% variables_a_eliminar)]
intercept<-as.matrix((rep(rcoefi[1], nrow(house_test))))
betas<-(as.matrix(house_test_prediction) %*% as.matrix(ridgecoef))
price_log<-intercept+betas
house_test$price=exp(price_log)
write.csv(house_test, file = "data/house_test_withprices.csv")
## -------------------------------------------------------------------------
variables <- c("bedrooms", "bathrooms", "sqft-living15", "sqft-lot15", "sqft-above", "yr_built", "yr_renovated", "renovated", "date", "waterfront", "view", "condition", "sqft_basement", "basement")
Lambda = 5
Pruebas = 100
Coeficientes = matrix(0, nrow=Pruebas, ncol=length(variables)+1)
Coeficientes = as.data.frame(Coeficientes)
colnames(Coeficientes) = c("termino_independiente", variables)
SCE_TRAIN1_modeloRidge = c()
STC_TRAIN1_modeloRidge = c()
R2_TRAIN1_modeloRidge = c()
SCE_TEST1_modeloRidge = c()
STC_TEST1_modeloRidge = c()
R2_TEST1_modeloRidge = c()
for (i in 1:Pruebas) {
modelo_glmnet=glmnet(x=as.matrix(Train[,variables]),y=Train$price_log,lambda=Lambda*(i-1)/Pruebas,alpha=0)
Coeficientes[i,]=c(modelo_glmnet$a0,as.vector(modelo_glmnet$beta))
prediccionesTrain=predict(modelo_glmnet,newx = as.matrix(Train[,variables]))
SCE_TRAIN1_modeloRidge=c(SCE_TRAIN1_modeloRidge,sum((Train$price_log-prediccionesTrain)^2))
STC_TRAIN1_modeloRidge=c(STC_TRAIN1_modeloRidge,sum((Train$price_log-mean(Train$price_log))^2))
R2_TRAIN1_modeloRidge=c(R2_TRAIN1_modeloRidge,1-sum((Train$price_log-prediccionesTrain)^2)/sum((Train$price_log-mean(Train$price_log))^2))
prediccionesTest=predict(modelo_glmnet,newx = as.matrix(Test[,variables]))
SCE_TEST1_modeloRidge=c(SCE_TEST1_modeloRidge,sum((Test$price_log-prediccionesTest)^2))
STC_TEST1_modeloRidge=c(STC_TEST1_modeloRidge,sum((Test$price_log-mean(Test$price_log))^2))
R2_TEST1_modeloRidge=c(R2_TEST1_modeloRidge,1-sum((Test$price_log-prediccionesTest)^2)/sum((Test$price_log-mean(Test$price_log))^2))
}
setwd("//home/juan/ciff/AnalisisEstadistico/AnalisisEstadistico")
getwd()
Ventas = read.csv("data/house_train.csv", stringsAsFactors=FALSE, sep=",")
str(Ventas)
head(Ventas)
summary(Ventas)
labels <- colnames(Ventas)
for (label in labels) {
numvalores <- nrow(unique(Ventas[label]))
cat('- Número de valores distintos de', label, ':', numvalores, '\n')
}
print('- Valores únicos de algunas variables')
for (label in labels) {
numvalores <- nrow(unique(Ventas[label]))
if(numvalores < 10) {
print(unique(Ventas[label]))
}
}
Ventas[!complete.cases(Ventas),]
boxplot(table(Ventas$price))
ggplot(data=Ventas) + geom_histogram(aes(x=Ventas$price), fill = "black", color = "grey") + ggtitle("Price Distribution") + xlab("Price") + ylab("Frequency")
dev.off()
png("images/var_price_boxplot.png")
boxplot(table(Ventas$price))
dev.off()
png("images/var_price_ggplot.png")
ggplot(data=Ventas) + geom_histogram(aes(x=Ventas$price), fill = "black", color = "grey") + ggtitle("Price Distribution") + xlab("Price") + ylab("Frequency")
dev.off()
Ventas$price_log <- log(Ventas$price)
boxplot(Ventas$price_log)
ggplot(data=Ventas) + geom_histogram(aes(x=Ventas$price_log), fill = "black", color = "grey") + ggtitle("Price Distribution") + xlab("Price") + ylab("Frequency")
dev.off()
png("images/var_price_boxplot_log.png")
boxplot(Ventas$price_log)
dev.off()
png("images/var_price_ggplot_log.png")
ggplot(data=Ventas) + geom_histogram(aes(x=Ventas$price_log), fill = "black", color = "grey") + ggtitle("Price Distribution") + xlab("Price") + ylab("Frequency")
dev.off()
boxplot(table(Ventas$sqft_living))
ggplot(data=Ventas) + geom_histogram(aes(x=Ventas$sqft_living), fill = "black", color = "grey") + ggtitle("Sqft living Distribution") + xlab("Sqft living") + ylab("Frequency")
dev.off()
png("images/var_sqft_living_boxplot.png")
boxplot(table(Ventas$sqft_living))
dev.off()
png("images/var_sqft_living_ggplot.png")
ggplot(data=Ventas) + geom_histogram(aes(x=Ventas$sqft_living), fill = "black", color = "grey") + ggtitle("Sqft living Distribution") + xlab("Sqft living") + ylab("Frequency")
dev.off()
Ventas$sqft_living_log <- log(Ventas$sqft_living)
boxplot(Ventas$sqft_living_log)
ggplot(data=Ventas) + geom_histogram(aes(x=Ventas$sqft_living_log), fill = "black", color = "grey") + ggtitle("Price Distribution") + xlab("Price") + ylab("Frequency")
dev.off()
png("images/var_sqft_living_boxplot_log.png")
boxplot(Ventas$sqft_living_log)
dev.off()
png("images/var_sqft_living_ggplot_log.png")
ggplot(data=Ventas) + geom_histogram(aes(x=Ventas$sqft_living_log), fill = "black", color = "grey") + ggtitle("Price Distribution") + xlab("Price") + ylab("Frequency")
dev.off()
modelo1 = lm(price ~ sqft_living, data = Ventas)
summary(modelo1)
par(mfrow = c(2, 2))
plot(modelo1$residuals)
smoothScatter(modelo1$residuals)
hist(modelo1$residuals)
qqnorm(modelo1$residuals); qqline(modelo1$residuals, col = 2)
dev.off()
png("images/residuos_lm1.png")
par(mfrow = c(2, 2))
plot(modelo1$residuals)
smoothScatter(modelo1$residuals)
hist(modelo1$residuals)
qqnorm(modelo1$residuals); qqline(modelo1$residuals, col = 2)
dev.off()
confint(modelo1, level = 0.95)
modelo2 = lm(price_log ~ sqft_living, data = Ventas)
summary(modelo2)
### Generamos las gráficas de análisis de residuos
par(mfrow = c(2, 2))
plot(modelo2$residuals)
smoothScatter(modelo2$residuals)
hist(modelo2$residuals)
qqnorm(modelo2$residuals); qqline(modelo2$residuals, col = 2)
# En el análisis de los residuos parece verse que se cumplen los supuestos de normalidad y homogeneidad, aunque hay una gran presencia de outliers.
# La hipótesis de linealidad también se cumple. R² = 0.48.
### Exportamos a fichero las gráficas de análisis de residuos
dev.off()
png("images/residuos_lm2.png")
par(mfrow = c(2, 2))
plot(modelo2$residuals)
smoothScatter(modelo2$residuals)
hist(modelo2$residuals)
qqnorm(modelo2$residuals); qqline(modelo2$residuals, col = 2)
dev.off()
### Obtenemos el intervalo de confianza para el 95%
confint(modelo2, level = 0.95)
### Creamos el modelo
modelo3 = lm(price ~ sqft_living_log, data = Ventas)
summary(modelo3)
### Generamos las gráficas de análisis de residuos
par(mfrow = c(2, 2))
plot(modelo3$residuals)
smoothScatter(modelo3$residuals)
hist(modelo3$residuals)
qqnorm(modelo3$residuals); qqline(modelo3$residuals, col = 2)
# En el análisis de los residuos se puede ver que no se cumplen los supuestos de homogeneidad ni normalidad, por lo que la aplicación de OLS no es correcta.
### Exportamos a fichero las gráficas de análisis de residuos
dev.off()
png("images/residuos_lm3.png")
par(mfrow = c(2, 2))
plot(modelo3$residuals)
smoothScatter(modelo3$residuals)
hist(modelo3$residuals)
qqnorm(modelo3$residuals); qqline(modelo3$residuals, col = 2)
dev.off()
### Obtenemos el intervalo de confianza para el 95%
confint(modelo3, level = 0.95)
### Creamos el modelo
modelo4 = lm(price_log ~ sqft_living_log, data = Ventas)
summary(modelo4)
### Generamos las gráficas de análisis de residuos
par(mfrow = c(2, 2))
plot(modelo4$residuals)
smoothScatter(modelo4$residuals)
hist(modelo4$residuals)
qqnorm(modelo4$residuals); qqline(modelo4$residuals, col = 2)
# En el análisis de los residuos parece verse que se cumplen bastante bien los supuestos de normalidad y homogeneidad.
# La hipótesis de linealidad también se cumple. R² = 0.45.
### Exportamos a fichero las gráficas de análisis de residuos
dev.off()
png("images/residuos_lm4.png")
par(mfrow = c(2, 2))
plot(modelo4$residuals)
smoothScatter(modelo4$residuals)
hist(modelo4$residuals)
qqnorm(modelo4$residuals); qqline(modelo4$residuals, col = 2)
dev.off()
### Obtenemos el intervalo de confianza para el 95%
confint(modelo4, level = 0.95)
par(mfrow = c(2, 2))
qqnorm(modelo1$residuals, main='Normal Q-Q Plot - Modelo 1'); qqline(modelo1$residuals, col = 2)
qqnorm(modelo2$residuals, main='Normal Q-Q Plot - Modelo 2'); qqline(modelo2$residuals, col = 2)
qqnorm(modelo3$residuals, main='Normal Q-Q Plot - Modelo 3'); qqline(modelo3$residuals, col = 2)
qqnorm(modelo4$residuals, main='Normal Q-Q Plot - Modelo 4'); qqline(modelo4$residuals, col = 2)
dev.off()
png("images/comparativa_qqnorm.png")
par(mfrow = c(2, 2))
qqnorm(modelo1$residuals, main='Normal Q-Q Plot - Modelo 1'); qqline(modelo1$residuals, col = 2)
qqnorm(modelo2$residuals, main='Normal Q-Q Plot - Modelo 2'); qqline(modelo2$residuals, col = 2)
qqnorm(modelo3$residuals, main='Normal Q-Q Plot - Modelo 3'); qqline(modelo3$residuals, col = 2)
qqnorm(modelo4$residuals, main='Normal Q-Q Plot - Modelo 4'); qqline(modelo4$residuals, col = 2)
dev.off()
### Métricas R² y R² ajustado
summary(modelo2)
# Multiple R-squared:  0.4828,	Adjusted R-squared:  0.4828
summary(modelo4)
# Multiple R-squared:  0.4546,	Adjusted R-squared:  0.4546
### Métrica AIC
AIC(modelo2)
# 15587.46
AIC(modelo4)
# 16510.51
### Métrica BIC
BIC(modelo2)
# 15610.75
BIC(modelo4)
# 16533.8
# Mostramos ahora en un gráfico la distribución y la recta de regresión con histogramas marginales
plot_center = ggplot(Ventas, aes(x=sqft_living, y=price_log)) + geom_point() + geom_smooth(method="lm")
ggMarginal(plot_center, type="histogram")
dev.off()
png("images/ggMarginal.png")
plot_center = ggplot(Ventas, aes(x=sqft_living, y=price_log)) + geom_point() + geom_smooth(method="lm")
ggMarginal(plot_center, type="histogram")
dev.off()
table(Ventas$bedrooms)
table(Ventas$bathrooms)
table(Ventas$fllors)
ggpairs(Ventas[, c("bedrooms", "bathrooms", "floors", "sqft_living", "price")])
dev.off()
png("images/ggpairs_interior.png")
ggpairs(Ventas[, c("bedrooms", "bathrooms", "floors", "sqft_living", "price")])
dev.off()
# Excluiremos del modelo las siguientes variables:
# - bedrooms y bathrooms: porque están muy correlacionadas con sqft_living (0.60 y 0.76) y entre sí (0.53).
table(Ventas$waterfront)
table(Ventas$view)
ggpairs(Ventas[, c("waterfront", "view", "price")])
dev.off()
png("images/ggpairs_exterior.png")
ggpairs(Ventas[, c("waterfront", "view", "price")])
dev.off()
table(Ventas$sqft_lot)
table(Ventas$sqft_above)
table(Ventas$sqft_basement==0)
table(Ventas$sqft_living15)
table(Ventas$sqft_lot15)
# La variable sqft_basement parece hacer referencia a la superficie del "sótano", y vemos que hay 10.552 viviendas que tienen ese valor a 0, por lo que vamos a crear una variable dummy.
Ventas$basement<-(ifelse(Ventas$sqft_basement==0,0,1))
ggpairs(Ventas[, c("sqft_lot", "sqft_above", "basement", "sqft_living15", "sqft_lot15", "sqft_living", "price")])
dev.off()
png("images/ggpairs_superficie.png")
ggpairs(Ventas[, c("sqft_lot", "sqft_above", "basement", "sqft_living15", "sqft_lot15", "sqft_living", "price")])
dev.off()
table(Ventas$date)
table(Ventas$yr_built)
table(Ventas$yr_renovated==0)
# Convertimos la información de la variable date en fechas válidas
Ventas$date<-as.Date(Ventas$date,"%Y%m%d")
# Vemos que hay 724 viviendas reformadas y 16.660 sin reformar, por lo que vamos a crear una variable dummy.
Ventas$renovated<-(ifelse(Ventas$yr_renovated==0,0,1))
ggpairs(Ventas[, c("yr_built", "renovated", "date", "price")])
dev.off()
png("images/ggpairs_fechas.png")
ggpairs(Ventas[, c("yr_built", "renovated", "date", "price")])
dev.off()
# Excluiremos del modelo las siguientes variables:
# - yr_built, yr_renovated y date: por su baja correlación con price.
table(Ventas$zipcode)
table(Ventas$lat)
table(Ventas$long)
ggpairs(Ventas[, c("zipcode", "lat", "long", "price")])
dev.off()
png("images/ggpairs_localizacion.png")
ggpairs(Ventas[, c("zipcode", "lat", "long", "price")])
dev.off()
# Excluiremos del modelo las siguientes variables:
# - Zipcode: porque tiene muchos niveles (70).
table(Ventas$condition)
table(Ventas$grade)
ggpairs(Ventas[, c("condition", "grade", "price")])
dev.off()
png("images/ggpairs_desconocidas.png")
ggpairs(Ventas[, c("condition", "grade", "price")])
dev.off()
Ventas2 <- Ventas
variables_a_excluir <- c("id", "price", "bedrooms", "bathrooms", "sqft-living15", "sqft-lot15", "sqft-above", "yr_built", "yr_renovated", "renovated", "date", "waterfront", "view", "condition", "sqft_basement", "basement")
Ventas2 <- Ventas2[ , !(names(Ventas2) %in% variables_a_excluir)]
set.seed(12357)
subsets = sample.split(Ventas2$price_log, SplitRatio = 0.7)
Train = subset(Ventas2, subsets == TRUE)
Test = subset(Ventas2, subsets == FALSE)
modelo = lm(price_log~., data=Train)
summary(modelo)
par(mfrow = c(2, 2))
plot(modelo)
dev.off()
png("images/modelo_train.png")
par(mfrow = c(2, 2))
plot(modelo)
dev.off()
modelo_r <- rlm(price_log~., data=Train)
summary(modelo_r)
coef(modelo)
coef(modelo_r)
Train$prediccion = predict(modelo, type="response")
R2_Train = 1 - sum((Train$price_log-Train$prediccion)^2)/sum((Train$price_log-mean(Train$price_log))^2)
R2_Train
Test$prediccion = predict(modelo,newdata=Test,type="response")
R2_Test = 1 - sum((Test$price_log-Test$prediccion)^2)/sum((Test$price_log-mean(Test$price_log))^2)
R2_Test
summary(modelo)$r.squared
summary(modelo)$adj.r.squared
dropscor <- c("lat","long","zipcode", "price_log", "logsqft_lot", "prediccion")
traincor<-Train[ , !(names(Train) %in% dropscor)]
cor(traincor)
cor(traincor)
variables <- c("bedrooms", "bathrooms", "sqft-living15", "sqft-lot15", "sqft-above", "yr_built", "yr_renovated", "renovated", "date", "waterfront", "view", "condition", "sqft_basement", "basement")
Lambda = 5
Pruebas = 100
Coeficientes = matrix(0, nrow=Pruebas, ncol=length(variables)+1)
Coeficientes = as.data.frame(Coeficientes)
colnames(Coeficientes) = c("termino_independiente", variables)
SCE_TRAIN1_modeloRidge = c()
STC_TRAIN1_modeloRidge = c()
R2_TRAIN1_modeloRidge = c()
SCE_TEST1_modeloRidge = c()
STC_TEST1_modeloRidge = c()
R2_TEST1_modeloRidge = c()
for (i in 1:Pruebas) {
modelo_glmnet=glmnet(x=as.matrix(Train[,variables]),y=Train$price_log,lambda=Lambda*(i-1)/Pruebas,alpha=0)
Coeficientes[i,]=c(modelo_glmnet$a0,as.vector(modelo_glmnet$beta))
prediccionesTrain=predict(modelo_glmnet,newx = as.matrix(Train[,variables]))
SCE_TRAIN1_modeloRidge=c(SCE_TRAIN1_modeloRidge,sum((Train$price_log-prediccionesTrain)^2))
STC_TRAIN1_modeloRidge=c(STC_TRAIN1_modeloRidge,sum((Train$price_log-mean(Train$price_log))^2))
R2_TRAIN1_modeloRidge=c(R2_TRAIN1_modeloRidge,1-sum((Train$price_log-prediccionesTrain)^2)/sum((Train$price_log-mean(Train$price_log))^2))
prediccionesTest=predict(modelo_glmnet,newx = as.matrix(Test[,variables]))
SCE_TEST1_modeloRidge=c(SCE_TEST1_modeloRidge,sum((Test$price_log-prediccionesTest)^2))
STC_TEST1_modeloRidge=c(STC_TEST1_modeloRidge,sum((Test$price_log-mean(Test$price_log))^2))
R2_TEST1_modeloRidge=c(R2_TEST1_modeloRidge,1-sum((Test$price_log-prediccionesTest)^2)/sum((Test$price_log-mean(Test$price_log))^2))
}
